{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import sys\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import HTML\n",
    "import jinja2 as ja\n",
    "from matplotlib import rcParams, rc, font_manager\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "import json\n",
    "from os.path import expanduser\n",
    "\n",
    "from Chandra.Time import DateTime\n",
    "from Ska.engarchive import fetch_eng as fetch\n",
    "\n",
    "home = expanduser(\"~\")\n",
    "sys.path.append(home + '/AXAFLIB/pylimmon/')\n",
    "import pylimmon\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_violations(thermdict, t1, t2):\n",
    "    \"\"\"Check a list of MSIDs for limit/expected state violations.\n",
    "    \n",
    "    :param thermdict: Dictionary of MSID information (MSID name, condition type, etc.)\n",
    "    :param t1: String containing start date in HOSC format\n",
    "    :param t2: String containgin stop date in HOSC format\n",
    "    \n",
    "    \"\"\"\n",
    "    t1 = DateTime(t1).date\n",
    "    t2 = DateTime(t2).date\n",
    "\n",
    "    allviolations = {}\n",
    "    missingmsids = []\n",
    "    checkedmsids = []\n",
    "    for key in thermdict.keys():\n",
    "        greta_msid = thermdict[key]['greta_msid']\n",
    "        try:\n",
    "            if thermdict[key]['type'] == 'limit':\n",
    "                if \"wide\" in greta_msid.lower():\n",
    "                    violations = handle_widerange_cases(key, t1, t2, greta_msid)\n",
    "                    checkedmsids.append(key)\n",
    "                else:\n",
    "                    violations = pylimmon.check_limit_msid(key, t1, t2, greta_msid=greta_msid)\n",
    "                    checkedmsids.append(key)\n",
    "            elif thermdict[key]['type'] == 'expst':\n",
    "                violations = pylimmon.check_state_msid(key, t1, t2, greta_msid=greta_msid)\n",
    "                checkedmsids.append(key)\n",
    "                \n",
    "            if len(violations) > 0:\n",
    "                allviolations[key] = process_violations(key, violations)\n",
    "            \n",
    "        except IndexError:\n",
    "            print('{} not in DB'.format(key))\n",
    "            missingmsids.append(key)\n",
    "\n",
    "    return allviolations, missingmsids, checkedmsids\n",
    "\n",
    "def handle_widerange_cases(key, t1, t2, greta_msid):\n",
    "    \"\"\"Handle special widerange MSIDs.\n",
    "    \n",
    "    :param key: Name of MSID as represented in Ska Engineering Archive\n",
    "    :param t1: String containing start time in HOSC format\n",
    "    :param t2: String containgin stop time in HOSC format\n",
    "    :greta_msid: Name of MSID as represented in GRETA\n",
    "    \n",
    "    Note: Some MSID names differ between Ska and GRETA. Widerange MSIDs are one such case. For example\n",
    "    OOBTHR35 is used for this measurement in both Ska and GRETA before this MSID was switched to \n",
    "    widerange read mode. Afterwards GRETA uses OOBTHR35_WIDE whereas Ska still uses OOBTHR35 for \n",
    "    continuity.\n",
    "    \"\"\"\n",
    "    if DateTime(t2).secs <= DateTime('2014:342:16:30:00').secs:\n",
    "        violations = pylimmon.check_limit_msid(key, t1, t2, greta_msid=key)\n",
    "    elif DateTime(t1).secs >= DateTime('2014:342:16:33:00').secs:\n",
    "        violations = pylimmon.check_limit_msid(key, t1, t2, greta_msid=greta_msid)\n",
    "    else:\n",
    "        t2_a = np.min((DateTime(t2).secs, DateTime('2014:342:16:30:00').secs))\n",
    "        violations = pylimmon.check_limit_msid(key, t1, t2_a, greta_msid=key)\n",
    "        t1_b = np.min((DateTime(t2).secs, DateTime('2014:342:16:33:00').secs))\n",
    "        violations_b = pylimmon.check_limit_msid(key, t1_b, t2, greta_msid=greta_msid)\n",
    "\n",
    "        violations.extend(violations_b)\n",
    "        \n",
    "    return violations\n",
    "\n",
    "def process_violations(msid, violations):\n",
    "    \"\"\"Add contextual information for any limit/expected state violations.\n",
    "    \n",
    "    :param msid: Current mnemonic\n",
    "    :param violations: List of individual violations (list of tuples)\n",
    "    \n",
    "    \"\"\"\n",
    "    data = fetch.Msid(msid, violations[0][0][0], violations[0][0][-1], stat='5min')\n",
    "    try:\n",
    "        desc = data.tdb.technical_name\n",
    "    except:\n",
    "        desc = 'No Description in TDB'\n",
    "        \n",
    "    violation_dict = {}\n",
    "    for v in violations:\n",
    "        limtype = v[-1]\n",
    "        if 'high' in limtype.lower():\n",
    "            if limtype not in violation_dict.keys():\n",
    "                violation_dict.update({limtype:{'starttime':v[0][0], 'stoptime':v[0][-1], 'num_excursions':1,\n",
    "                                                'extrema':np.max(v[1]), 'limit':v[2][0], 'setid':v[3][0]}})\n",
    "            else:\n",
    "                violation_dict[limtype]['extrema'] = np.max((np.max(v[1]), violation_dict[limtype]['extrema']))\n",
    "                violation_dict[limtype]['starttime'] = np.min((v[0][0], violation_dict[limtype]['starttime']))\n",
    "                violation_dict[limtype]['stoptime'] = np.max((v[0][0], violation_dict[limtype]['stoptime']))\n",
    "                violation_dict[limtype]['num_excursions'] = violation_dict[limtype]['num_excursions'] + 1\n",
    "                \n",
    "        elif 'low' in limtype.lower():\n",
    "            if limtype not in violation_dict.keys():\n",
    "                violation_dict.update({limtype:{'starttime':v[0][0], 'stoptime':v[0][-1], 'num_excursions':1,\n",
    "                                                'extrema':np.min(v[1]), 'limit':v[2][0], 'setid':v[3][0]}})\n",
    "            else:\n",
    "                violation_dict[limtype]['extrema'] = np.min((np.min(v[1]), violation_dict[limtype]['extrema']))\n",
    "                violation_dict[limtype]['starttime'] = np.min((v[0][0], violation_dict[limtype]['starttime']))\n",
    "                violation_dict[limtype]['stoptime'] = np.max((v[0][0], violation_dict[limtype]['stoptime']))\n",
    "                violation_dict[limtype]['num_excursions'] = violation_dict[limtype]['num_excursions'] + 1\n",
    "\n",
    "        elif 'state' in limtype.lower():\n",
    "            if limtype not in violation_dict.keys():\n",
    "                violation_dict.update({limtype:{'starttime':v[0][0], 'stoptime':v[0][-1], 'num_excursions':1,\n",
    "                                                'extrema':v[1][0], 'limit':v[2][0], 'setid':v[3][0]}})\n",
    "            else:\n",
    "                violation_dict[limtype]['starttime'] = np.min((v[0][0], violation_dict[limtype]['starttime']))\n",
    "                violation_dict[limtype]['stoptime'] = np.max((v[0][0], violation_dict[limtype]['stoptime']))\n",
    "                violation_dict[limtype]['num_excursions'] = violation_dict[limtype]['num_excursions'] + 1\n",
    "\n",
    "                \n",
    "    for limittype in ['warning_low', 'caution_low', 'caution_high', 'warning_high', 'state']:\n",
    "        if limittype in violation_dict.keys():\n",
    "            violation_dict[limittype]['duration'] = (violation_dict[limittype]['stoptime'] \n",
    "                - violation_dict[limittype]['starttime']) / 3600.\n",
    "            violation_dict[limittype]['description'] = desc\n",
    "            violation_dict[limittype]['startdate'] = DateTime(violation_dict[limittype]['starttime']).date\n",
    "            violation_dict[limittype]['stopdate'] = DateTime(violation_dict[limittype]['stoptime']).date\n",
    "            \n",
    "    return violation_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thermdict, missing, notinarchive = pickle.load(open(home + '/AXAFDATA/weekly_report_data/thermalmsiddata.pkl','r'))\n",
    "\n",
    "t1 = DateTime('2015:265:20:00:00.000').date\n",
    "t2 = DateTime('2015:266:00:00:00.000').date\n",
    "dayrange = (t1[:9] + '-' + t2[:9]).replace(':', '')\n",
    "\n",
    "allviolations, missingmsids, checkedmsids = check_violations(thermdict, t1, t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hours = (DateTime(t2).secs - DateTime(t1).secs)/3600.\n",
    "print('\\nChecked {} MSIDs at full resolution over {} hour period, {} MSIDs left unchecked (missing)\\n'.format(\n",
    "        len(checkedmsids), hours, len(missingmsids)) )\n",
    "\n",
    "env = ja.Environment(loader=ja.FileSystemLoader('./templates'))\n",
    "template = env.get_template('index.htm')\n",
    "webpage = template.render(dayrange=dayrange, violations=allviolations)\n",
    "HTML(webpage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
